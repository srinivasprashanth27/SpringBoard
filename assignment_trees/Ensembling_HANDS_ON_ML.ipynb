{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns=None\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score,auc,roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 61) (1000,)\n",
      "Train Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       491\n",
      "           1       1.00      1.00      1.00       209\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       700\n",
      "   macro avg       1.00      1.00      1.00       700\n",
      "weighted avg       1.00      1.00      1.00       700\n",
      "\n",
      "Train confusion Matrix\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          491    0\n",
      "1            0  209\n",
      "Test Confusion Matrix\n",
      "Predicted    0   1\n",
      "Actual            \n",
      "0          149  60\n",
      "1           46  45\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74       209\n",
      "           1       0.43      0.49      0.46        91\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       300\n",
      "   macro avg       0.60      0.60      0.60       300\n",
      "weighted avg       0.66      0.65      0.65       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "german_df=pd.read_csv('GermanCredit.csv')\n",
    "german_df.head()\n",
    "german_df.isnull().sum()[german_df.isnull().sum()!=0]#No missing values\n",
    "list(german_df.columns)\n",
    "german_df.dtypes.value_counts()\n",
    "german_df.Class.value_counts()\n",
    "y=german_df.Class\n",
    "x=german_df.drop('Class',axis=1)\n",
    "print(x.shape,y.shape)\n",
    "y=y.map({'Good':0,'Bad':1})\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "clf=DecisionTreeClassifier()\n",
    "# clf.fit(x_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,precision_score,recall_score\n",
    "clf.fit(x_train,y_train)\n",
    "print('Train Classification Report: ')\n",
    "print(classification_report(y_train,clf.predict(x_train)))\n",
    "print('Train confusion Matrix')\n",
    "print(pd.crosstab(y_train,clf.predict(x_train),rownames=['Actual'],colnames=['Predicted']))\n",
    "print('Test Confusion Matrix')\n",
    "print(pd.crosstab(y_test,clf.predict(x_test),colnames=['Predicted'],rownames=['Actual']))\n",
    "print('Test Classification Report')\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison Tree with Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 61) (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       491\n",
      "           1       1.00      1.00      1.00       209\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       700\n",
      "   macro avg       1.00      1.00      1.00       700\n",
      "weighted avg       1.00      1.00      1.00       700\n",
      "\n",
      "Train confusion Matrix\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          491    0\n",
      "1            0  209\n",
      "Test Confusion Matrix\n",
      "Predicted    0   1\n",
      "Actual            \n",
      "0          155  54\n",
      "1           44  47\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       209\n",
      "           1       0.47      0.52      0.49        91\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       300\n",
      "   macro avg       0.62      0.63      0.62       300\n",
      "weighted avg       0.68      0.67      0.68       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "german_df=pd.read_csv('GermanCredit.csv')\n",
    "german_df.head()\n",
    "german_df.isnull().sum()[german_df.isnull().sum()!=0]#No missing values\n",
    "list(german_df.columns)\n",
    "german_df.dtypes.value_counts()\n",
    "german_df.Class.value_counts()\n",
    "y=german_df.Class\n",
    "x=german_df.drop('Class',axis=1)\n",
    "print(x.shape,y.shape)\n",
    "y=y.map({'Good':0,'Bad':1})\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "scaler=StandardScaler()\n",
    "x_train.iloc[:,0:7]=scaler.fit_transform(x_train.iloc[:,0:7])\n",
    "x_test.iloc[:,0:7]=scaler.transform(x_test.iloc[:,0:7])\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,precision_score,recall_score\n",
    "clf.fit(x_train,y_train)\n",
    "print('Train Classification Report: ')\n",
    "print(classification_report(y_train,clf.predict(x_train)))\n",
    "print('Train confusion Matrix')\n",
    "print(pd.crosstab(y_train,clf.predict(x_train),rownames=['Actual'],colnames=['Predicted']))\n",
    "print('Test Confusion Matrix')\n",
    "print(pd.crosstab(y_test,clf.predict(x_test),colnames=['Predicted'],rownames=['Actual']))\n",
    "print('Test Classification Report')\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Scaling Turns out to be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7733333333333333\n",
      "RandomForestClassifier 0.78\n",
      "SVC 0.75\n",
      "VotingClassifier 0.7766666666666666\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42,probability=True)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the optimal number of trees by using Staged Predict Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf=GradientBoostingClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_scores=[f1_score(y_test,y_val) for y_val in clf.staged_predict(x_test)]\n",
    "np.argmax(f1_scores)#Staged predict gives predictions at each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is also possible to early stopping by stopping training at optimal number instead of training for large predictors and finding the optimal number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       491\n",
      "           1       0.96      0.77      0.86       209\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       700\n",
      "   macro avg       0.94      0.88      0.90       700\n",
      "weighted avg       0.93      0.92      0.92       700\n",
      "\n",
      "Train confusion Matrix\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          485    6\n",
      "1           48  161\n",
      "Test Confusion Matrix\n",
      "Predicted    0   1\n",
      "Actual            \n",
      "0          191  18\n",
      "1           49  42\n",
      "Test Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       209\n",
      "           1       0.70      0.46      0.56        91\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       300\n",
      "   macro avg       0.75      0.69      0.70       300\n",
      "weighted avg       0.77      0.78      0.76       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp=MLPClassifier()\n",
    "mlp.fit(x_train,y_train)\n",
    "print('Train Classification Report: ')\n",
    "print(classification_report(y_train,clf.predict(x_train)))\n",
    "print('Train confusion Matrix')\n",
    "print(pd.crosstab(y_train,clf.predict(x_train),rownames=['Actual'],colnames=['Predicted']))\n",
    "print('Test Confusion Matrix')\n",
    "print(pd.crosstab(y_test,clf.predict(x_test),colnames=['Predicted'],rownames=['Actual']))\n",
    "print('Test Classification Report')\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP is performing better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

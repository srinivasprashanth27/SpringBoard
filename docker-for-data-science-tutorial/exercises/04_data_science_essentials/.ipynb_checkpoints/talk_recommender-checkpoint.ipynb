{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talk Recommender - Pycon 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 32 tuotorials, 12 sponsor workshops, 16 talks at the education summit, and 95 talks at the main conference - Pycon has a lot to offer. Reading through all the talk descriptions and filtering out the ones that you should go to is a tedious process. But not anymore.\n",
    "\n",
    "## Introducing TalkRecommender\n",
    "Talk recommender is a recommendation system that recommends talks from this year's Pycon based on the ones that you went to last year.  This way you don't waste any time preparing a schedule and get to see the talks that matter the most to you! \n",
    "\n",
    "As shown in the demo, the users are asked to label previous year's talks into two categories - the one that they went to in person, and the ones they watched later online. Talk Recommender uses those labels to predict talks from this year that will be interesing to them. \n",
    "\n",
    "We will be using [`pandas`](https://pandas.pydata.org/) abd [`scikit-learn`](http://scikit-learn.org/) to build and the model.\n",
    "\n",
    "*Remember to click on Save and Checkpoint from the File menu to save changes you made to the notebook* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A: Load the data\n",
    "The data directory contains the snapshot of one such user's labeling - lets load that up and start with our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>presenters</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>location</th>\n",
       "      <th>talk_dt</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5 ways to deploy your Python web app in 2017</td>\n",
       "      <td>You’ve built a fine Python web application and...</td>\n",
       "      <td>Andrew T. Baker</td>\n",
       "      <td>2018-04-19 00:59:20.151875</td>\n",
       "      <td>2018-04-19 00:59:20.151875</td>\n",
       "      <td>Portland Ballroom 252–253</td>\n",
       "      <td>2017-05-08 15:15:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A gentle introduction to deep learning with Te...</td>\n",
       "      <td>Deep learning's explosion of spectacular resul...</td>\n",
       "      <td>Michelle Fullwood</td>\n",
       "      <td>2018-04-19 00:59:20.158338</td>\n",
       "      <td>2018-04-19 00:59:20.158338</td>\n",
       "      <td>Oregon Ballroom 203–204</td>\n",
       "      <td>2017-05-08 16:15:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aiosmtpd - A better asyncio based SMTP server</td>\n",
       "      <td>smtpd.py has been in the standard library for ...</td>\n",
       "      <td>Barry Warsaw</td>\n",
       "      <td>2018-04-19 00:59:20.161866</td>\n",
       "      <td>2018-04-19 00:59:20.161866</td>\n",
       "      <td>Oregon Ballroom 203–204</td>\n",
       "      <td>2017-05-08 14:30:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Algorithmic Music Generation</td>\n",
       "      <td>Music is mainly an artistic act of inspired cr...</td>\n",
       "      <td>Padmaja V Bhagwat</td>\n",
       "      <td>2018-04-19 00:59:20.165526</td>\n",
       "      <td>2018-04-19 00:59:20.165526</td>\n",
       "      <td>Portland Ballroom 251 &amp; 258</td>\n",
       "      <td>2017-05-08 17:10:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>An Introduction to Reinforcement Learning</td>\n",
       "      <td>Reinforcement learning (RL) is a subfield of m...</td>\n",
       "      <td>Jessica Forde</td>\n",
       "      <td>2018-04-19 00:59:20.169075</td>\n",
       "      <td>2018-04-19 00:59:20.169075</td>\n",
       "      <td>Portland Ballroom 252–253</td>\n",
       "      <td>2017-05-08 13:40:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1       5 ways to deploy your Python web app in 2017   \n",
       "1   2  A gentle introduction to deep learning with Te...   \n",
       "2   3      aiosmtpd - A better asyncio based SMTP server   \n",
       "3   4                       Algorithmic Music Generation   \n",
       "4   5          An Introduction to Reinforcement Learning   \n",
       "\n",
       "                                         description         presenters  \\\n",
       "0  You’ve built a fine Python web application and...    Andrew T. Baker   \n",
       "1  Deep learning's explosion of spectacular resul...  Michelle Fullwood   \n",
       "2  smtpd.py has been in the standard library for ...       Barry Warsaw   \n",
       "3  Music is mainly an artistic act of inspired cr...  Padmaja V Bhagwat   \n",
       "4  Reinforcement learning (RL) is a subfield of m...      Jessica Forde   \n",
       "\n",
       "                 date_created               date_modified  \\\n",
       "0  2018-04-19 00:59:20.151875  2018-04-19 00:59:20.151875   \n",
       "1  2018-04-19 00:59:20.158338  2018-04-19 00:59:20.158338   \n",
       "2  2018-04-19 00:59:20.161866  2018-04-19 00:59:20.161866   \n",
       "3  2018-04-19 00:59:20.165526  2018-04-19 00:59:20.165526   \n",
       "4  2018-04-19 00:59:20.169075  2018-04-19 00:59:20.169075   \n",
       "\n",
       "                      location                     talk_dt  year  label  \n",
       "0    Portland Ballroom 252–253  2017-05-08 15:15:00.000000  2017    0.0  \n",
       "1      Oregon Ballroom 203–204  2017-05-08 16:15:00.000000  2017    0.0  \n",
       "2      Oregon Ballroom 203–204  2017-05-08 14:30:00.000000  2017    1.0  \n",
       "3  Portland Ballroom 251 & 258  2017-05-08 17:10:00.000000  2017    0.0  \n",
       "4    Portland Ballroom 252–253  2017-05-08 13:40:00.000000  2017    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('data/talks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief description of the interesting fields.\n",
    "\n",
    "variable | description  \n",
    "------|------|\n",
    "`title`|Title of the talk\n",
    "`description`|Description of the talk\n",
    "`year`|Is it a `2017` talk or `2018`  \n",
    "`label`|`1` indicates the user preferred seeing the talk in person,<br> `0` indicates they would schedule it for later.\n",
    "\n",
    "Note all 2018 talks are set to 1. However they are only placeholders, and are not used in training the model. We will  use only 2017 data for training.\n",
    "\n",
    "Lets start by selecting the 2017 talk descriptions that were labeled by the user for watching in person.\n",
    "\n",
    "```python\n",
    "df[(df.year==2017) & (df.label==1)]['description']\n",
    "```\n",
    "\n",
    "Print the description of the talks that the user preferred watching in person. How many such talks are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise B: Feature Extraction\n",
    "In this step we build the feature set by tokenization, counting and normalization of the bi-grams from the text descriptions of the talk. You can find more information on text feature extraction [here](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) and TfidfVectorizer [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2017 talks will be used for training and the 2018 talks will we used for predicting. Set the values of `year_labeled` and `year_predict` to appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_labeled=2017\n",
    "year_predict=2018\n",
    "vectorized_text_labeled = vectorizer.fit_transform(df[df.year==year_labeled]['description'])\n",
    "vectorized_text_predict = vectorizer.transform(df[df.year==year_predict]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise C: Split into Training and Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split our data into training set and testing set. This allows us to do cross validation and avoid overfitting. Use the `train_test_split` method from `sklearn.model_selection` to split the `vectorized_text_labeled` into training and testing set with the test size as one third of the size (0.3) of the labeled.\n",
    "\n",
    "[Here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) is the documentation for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = df[df.year == 2017]['label']\n",
    "test_size=0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_text_labeled, labels, test_size=test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise D: Train the model\n",
    "Finally we get to the stage for training the model. We are going to use a linear [support vector classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) and check its accuracy by using the `classification_report` function. Note that we have not done any parameter tuning yet, so your model might not give you the best results. \n",
    "\n",
    "\n",
    "[Here](http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html) is some information for using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) for doing exhaustive search over specified parameter values of an estimator. _However, this is purely for reference and not needed for this exercise._\n",
    "\n",
    "Print out the `report` to see how well your model has been trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "report = sklearn.metrics.classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise E: Make Predictions\n",
    "Use the model to predict which 2018 talks the user should go to. \n",
    "\n",
    "Using the `predicted_talk_indexes` print out the talk id, description, presenters, title and location and talk date.\n",
    "How many talks should the user go to according to your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'foo':       id                                        description  \\\n",
       "  97    98  In this talk, you’ll learn about a category of...   \n",
       "  101  102  Writing quality Python code can be both tough ...   \n",
       "  102  103  Nowadays, there are many ways of building data...   \n",
       "  103  104  Behavior-Driven Development (BDD) is gaining p...   \n",
       "  105  106  You've used pytest and you've used mypy, but b...   \n",
       "  112  113  Want to know about the latest trends in the Py...   \n",
       "  115  116  Code reviews don't have to be a time consuming...   \n",
       "  118  119  Testing mobile applications is hard. Testing m...   \n",
       "  126  126  One of the most challenging and important thin...   \n",
       "  131  132  Are you an intermediate python developer looki...   \n",
       "  139  140  A function is a small chunk of code that does ...   \n",
       "  144  145  Questions and confusion about the Python packa...   \n",
       "  148  149  Those of us who have worked in software develo...   \n",
       "  149  150  What do AWS, GitHub, Travis CI, DockerHub, Goo...   \n",
       "  150  151  Python provides a powerful platform for workin...   \n",
       "  151  152  Each member of your project team uses somethin...   \n",
       "  152  153  If you’ve spent much time writing (or debuggin...   \n",
       "  154  155  Looking back at Python evolutions over the las...   \n",
       "  155  156  For 2 years, a family of three has traveled on...   \n",
       "  159  160  Occasionally we’ll find that some bit of Pytho...   \n",
       "  165  166  Stop writing crappy shell scripts—write crappy...   \n",
       "  167  168  Taking on leadership roles always includes new...   \n",
       "  171  172  Get under the hood and learn about Python's be...   \n",
       "  185  186  Know you should be doing testing but haven’t g...   \n",
       "  187  188  Many of us practice test driven development, a...   \n",
       "  \n",
       "                           presenters  \\\n",
       "  97     Philip James, Asheesh Laroia   \n",
       "  101                      Kyle Knapp   \n",
       "  102          Christopher Fonnesbeck   \n",
       "  103                   Andrew Knight   \n",
       "  105                    Hillel Wayne   \n",
       "  112  Dmitry Filippov, Ewa Jodlowska   \n",
       "  115                     Stacy Morse   \n",
       "  118                        Nir Arad   \n",
       "  126                      Lisa Roach   \n",
       "  131                 Nina Zakharenko   \n",
       "  139                  Jack Diederich   \n",
       "  144                   Dustin Ingram   \n",
       "  148                      Esther Nam   \n",
       "  149                 Miguel Grinberg   \n",
       "  150                 Jake VanderPlas   \n",
       "  151                   Carol Willing   \n",
       "  152           vigneshwer dhinakaran   \n",
       "  154                  Victor Stinner   \n",
       "  155             Justin Myles Holmes   \n",
       "  159                      Matt Davis   \n",
       "  165                  Larry Hastings   \n",
       "  167                   Scott Triglia   \n",
       "  171       Emily Morehouse-Valcarcel   \n",
       "  185       Brian Okken, Paul Everitt   \n",
       "  187                    Justin Crown   \n",
       "  \n",
       "                                                   title  \\\n",
       "  97    All in the timing: How side channel attacks work   \n",
       "  101                            Automating Code Quality   \n",
       "  102  Bayesian Non-parametric Models for Data Scienc...   \n",
       "  103                             Behavior-Driven Python   \n",
       "  105  Beyond Unit Tests: Taking Your Testing to the ...   \n",
       "  112  By the Numbers: Python Community Trends in 201...   \n",
       "  115         Code Reviews Using Art Critique Principles   \n",
       "  118  Controlling apples with snakes: Automating mob...   \n",
       "  126                    Demystifying the Patch Function   \n",
       "  131     Elegant Solutions For Everyday Python Problems   \n",
       "  139                             HOWTO Write a Function   \n",
       "  144  Inside the Cheeseshop: How Python Packaging Works   \n",
       "  148  One weird trick to becoming a better software ...   \n",
       "  149           Oops! I Committed My Password To GitHub!   \n",
       "  150  Performance Python: Seven Strategies for Optim...   \n",
       "  151                                   Practical Sphinx   \n",
       "  152               Pumping up Python modules using Rust   \n",
       "  154                          Python 3: ten years later   \n",
       "  155            Python across the USA: This is the Bus.   \n",
       "  159        Python Performance Investigation by Example   \n",
       "  165              Solve Your Problem With Sloppy Python   \n",
       "  167  Surviving (and thriving!) when you are overloaded   \n",
       "  171                                     The AST and Me   \n",
       "  185             Visual Testing with PyCharm and pytest   \n",
       "  187  \"WHAT IS THIS MESS?\" - Writing tests for pre-e...   \n",
       "  \n",
       "                        location                     talk_dt  \n",
       "  97            Grand Ballroom B  2018-03-29 17:10:00.000000  \n",
       "  101           Grand Ballroom A  2018-03-29 14:30:00.000000  \n",
       "  102  Global Center Ballroom AB  2018-03-29 13:40:00.000000  \n",
       "  103           Grand Ballroom A  2018-03-29 12:10:00.000000  \n",
       "  105               Room 26A/B/C  2018-03-29 12:10:00.000000  \n",
       "  112               Room 26A/B/C  2018-03-29 13:55:00.000000  \n",
       "  115           Grand Ballroom A  2018-03-29 10:50:00.000000  \n",
       "  118           Grand Ballroom A  2018-03-29 15:15:00.000000  \n",
       "  126           Grand Ballroom B  2018-03-29 12:10:00.000000  \n",
       "  131               Room 26A/B/C  2018-03-29 17:10:00.000000  \n",
       "  139               Room 26A/B/C  2018-03-29 12:10:00.000000  \n",
       "  144               Room 26A/B/C  2018-03-29 11:30:00.000000  \n",
       "  148  Global Center Ballroom AB  2018-03-29 12:10:00.000000  \n",
       "  149           Grand Ballroom C  2018-03-29 11:30:00.000000  \n",
       "  150           Grand Ballroom C  2018-03-29 11:30:00.000000  \n",
       "  151           Grand Ballroom A  2018-03-29 11:30:00.000000  \n",
       "  152  Global Center Ballroom AB  2018-03-29 13:50:00.000000  \n",
       "  154           Grand Ballroom B  2018-03-29 15:15:00.000000  \n",
       "  155           Grand Ballroom A  2018-03-29 14:35:00.000000  \n",
       "  159               Room 26A/B/C  2018-03-29 16:30:00.000000  \n",
       "  165           Grand Ballroom C  2018-03-29 10:50:00.000000  \n",
       "  167  Global Center Ballroom AB  2018-03-29 15:15:00.000000  \n",
       "  171           Grand Ballroom B  2018-03-29 15:15:00.000000  \n",
       "  185           Grand Ballroom A  2018-03-29 17:10:00.000000  \n",
       "  187  Global Center Ballroom AB  2018-03-29 12:10:00.000000  }]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_talks_vector = classifier.predict(vectorized_text_predict)\n",
    "df_2018 = df[df.year==2018]\n",
    "\n",
    "# Offset the rows by 2017 talks\n",
    "predicted_talk_indexes = predicted_talks_vector.nonzero()[0] + len(df[df.year==2017])\n",
    "# your solution goes here\n",
    "df.loc[predicted_talk_indexes,['id','description','presenters','title','location','talk_dt']]\n",
    "results=pd.DataFrame({'foo':[df.loc[predicted_talk_indexes,['id','description','presenters','title','location','talk_dt']]]})\n",
    "results.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise F: Expose it as a service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have pieces of the code ready, copy them together into the `model.py` file located in this folder, and rebuild your docker image. Copy the code from the above cells into the body of the `prediction` function.\n",
    "\n",
    "Lets rebuild the docker image and start an new container following the comments.\n",
    "\n",
    "In the following steps you will leave the jupyter notebook, and stop the container serving it. So save any changes you have done till this point.\n",
    "\n",
    "```\n",
    "docker stop <container_name>\n",
    "docker build -t recommender .\n",
    "docker run -p 8888:8888 -p 9000:9000 -v $(pwd):/app recommender\n",
    "```\n",
    "where `<container_name>` is the name of the container serving this jupyter notebook.\n",
    "\n",
    "The `api.py` file in this directory is a flask app that makes call to the `model.py` module and exposes the model built in the previous steps as a service. In order to start the flask server, open a new terminal and run the following command.\n",
    "\n",
    "```\n",
    "docker exec $(docker ps -ql) python api.py\n",
    "```\n",
    "Where `docker ps -ql` gets numeric id of the latest container id.\n",
    "\n",
    "Finally go to http://0.0.0.0:9000/predict to see the talks that were recommended for this user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise G: Pickle the model\n",
    "\n",
    "Finally we do not have to retrain our model anytime we have to make predictions. In most real life data science applications, the training phase is a time consuming proecss. We would seaprately train and serialize the model which is then exposed through the api to make the predictions. The `predict_api` directory of the TalkVoter app shows an approach where we wrap the model and seaprate out only calls to the prediction api to use the trained model instead of reprocessing any time there is a call to the api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "with open('talk_recommender.pkl', 'wb') as f:\n",
    "    joblib.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create the pickle file in your directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `joblib.load` function to read the `classifier` back from the `talk_recommender.pkl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
